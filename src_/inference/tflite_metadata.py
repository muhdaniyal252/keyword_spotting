from tflite_support.metadata_writers import audio_classifier
from tflite_support.metadata_writers import metadata_info
from tflite_support.metadata_writers import writer_utils
from tflite_support import metadata_schema_py_generated as _metadata_fb

model_buffer = writer_utils.load_file("/home/majam001/kws/alpha-kws/models/pless_sweep_mfcc40_5/model_3/tflite/model_3_pless_sweep_convmel_float32.tflite")

# Create general model information.
general_md = metadata_info.GeneralMd(
    name="KeywordSpottingwithNAS",
    version="v3",
    description="Detect keywords in audio",
    author="Mariam Jamal")

# Create input tensor information.
input_md = metadata_info.InputAudioTensorMd(
    name="input_audio",
    description=("Input audio tensor. The expected shape is (1, 44100) for the audio"
                 "The sample rate is 44.1 kHz."),
    sample_rate= 44100,
    channels = 1)

# Create output tensor information.
output_md = metadata_info.ClassificationTensorMd(
    name="output_classes",
    description="Output classes tensor. The shape is (1, 4) for your specific model.",
    label_files=[
        metadata_info.LabelFileMd(file_path="/home/majam001/kws/alpha-kws/models/pless_sweep_mfcc40_5/model_3/tflite/labels.txt",
                                  locale="en")
    ], 
    tensor_type=writer_utils.get_output_tensor_types(model_buffer)[0])

# Create the metadata writer.
audio_classifier_writer = audio_classifier.MetadataWriter
writer = audio_classifier_writer.create_from_metadata_info(
    model_buffer, general_md, input_md, output_md)

# Verify the metadata generated by metadata writer.
print(writer.get_metadata_json())

# Populate the metadata into the model.
_SAVE_TO_PATH = "/home/majam001/kws/alpha-kws/models/pless_sweep_mfcc40_5/model_3/tflite/model_3_pless_sweep_convmel_float32_with_metadata.tflite"
writer_utils.save_file(writer.populate(), _SAVE_TO_PATH)
