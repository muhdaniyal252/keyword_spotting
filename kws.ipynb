{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "UL42Hlss3sfl"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pathlib\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import wave\n",
        "import pandas as pd\n",
        "import librosa\n",
        "from scipy import signal\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_PATH = 'data/mini_speech_commands'\n",
        "\n",
        "data_dir = pathlib.Path(DATASET_PATH)\n",
        "if not data_dir.exists():\n",
        "    tf.keras.utils.get_file(\n",
        "        'mini_speech_commands.zip',\n",
        "        origin=\"http://storage.googleapis.com/download.tensorflow.org/data/mini_speech_commands.zip\",\n",
        "        extract=True,\n",
        "        cache_dir='.', cache_subdir='data')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dW5pe8F33ql",
        "outputId": "db4945ea-b974-4b0e-d43c-4141aadb31ff"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from http://storage.googleapis.com/download.tensorflow.org/data/mini_speech_commands.zip\n",
            "182082353/182082353 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "categories = {i:j for i,j in enumerate(filter(lambda x: x in ['stop', 'up', 'yes', 'down', 'no', 'left', 'right', 'go'],os.listdir(DATASET_PATH)))}\n",
        "categories"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2PoqevW39Il",
        "outputId": "2ca43ab7-7482-46b4-b98c-e36ecfcb78d0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'go',\n",
              " 1: 'stop',\n",
              " 2: 'left',\n",
              " 3: 'right',\n",
              " 4: 'up',\n",
              " 5: 'no',\n",
              " 6: 'yes',\n",
              " 7: 'down'}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(path):\n",
        "    data = list()\n",
        "    for idx, folder in categories.items():\n",
        "        folder_path = os.path.join(path,folder)\n",
        "        images = os.listdir(folder_path)\n",
        "        images = [os.path.join(folder_path,image) for image in images]\n",
        "        for image in images:\n",
        "            data.append([image,idx])\n",
        "    return data\n",
        "data = load_data(DATASET_PATH)"
      ],
      "metadata": {
        "id": "DMBXkty04fDF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random.shuffle(data)\n",
        "random.shuffle(data)"
      ],
      "metadata": {
        "id": "CBUJxnY94g6k"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sample_rate(d):\n",
        "    audio_path,label = d\n",
        "    with wave.open(audio_path, 'rb') as wav_file:\n",
        "        sample_rate = wav_file.getframerate()\n",
        "        num_frames = wav_file.getnframes()\n",
        "        duration = num_frames / sample_rate\n",
        "    return sample_rate,duration,label\n",
        "\n",
        "audio_info = [get_sample_rate(d) for d in data]\n",
        "df = pd.DataFrame(audio_info, columns =['sample_rate', 'duration','label'])"
      ],
      "metadata": {
        "id": "YloarUHI4i-U"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4OBHFsfF4kzE",
        "outputId": "2b762c49-0bb7-430d-ff94-060efdec2d45"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "label\n",
              "3    1000\n",
              "1    1000\n",
              "4    1000\n",
              "6    1000\n",
              "5    1000\n",
              "7    1000\n",
              "2    1000\n",
              "0    1000\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "l-UPow9g4mkF",
        "outputId": "db91e00b-b37e-4751-d58b-3aec428323c1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       sample_rate     duration        label\n",
              "count       8000.0  8000.000000  8000.000000\n",
              "mean       16000.0     0.983703     3.500000\n",
              "std            0.0     0.061426     2.291431\n",
              "min        16000.0     0.426687     0.000000\n",
              "25%        16000.0     1.000000     1.750000\n",
              "50%        16000.0     1.000000     3.500000\n",
              "75%        16000.0     1.000000     5.250000\n",
              "max        16000.0     1.000000     7.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e894b047-ee85-454e-a1a9-7f39bca176c5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sample_rate</th>\n",
              "      <th>duration</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>8000.0</td>\n",
              "      <td>8000.000000</td>\n",
              "      <td>8000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>16000.0</td>\n",
              "      <td>0.983703</td>\n",
              "      <td>3.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.061426</td>\n",
              "      <td>2.291431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>16000.0</td>\n",
              "      <td>0.426687</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>16000.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>16000.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>16000.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>5.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>16000.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>7.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e894b047-ee85-454e-a1a9-7f39bca176c5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e894b047-ee85-454e-a1a9-7f39bca176c5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e894b047-ee85-454e-a1a9-7f39bca176c5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-972d775d-e6aa-4500-92e4-2275b2645737\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-972d775d-e6aa-4500-92e4-2275b2645737')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-972d775d-e6aa-4500-92e4-2275b2645737 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"sample_rate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5952.190473142759,\n        \"min\": 0.0,\n        \"max\": 16000.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          8000.0,\n          16000.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"duration\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2828.1507784580403,\n        \"min\": 0.06142551465568253,\n        \"max\": 8000.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.9837025156249999,\n          1.0,\n          0.06142551465568253\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2827.2515351783513,\n        \"min\": 0.0,\n        \"max\": 8000.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          8000.0,\n          3.5,\n          5.25\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_mfcc(audio, sample_rate, n_mfcc=13):\n",
        "    audio = audio.copy()\n",
        "    audio[np.isnan(audio)] = 0.0\n",
        "    audio[np.isinf(audio)] = 0.0\n",
        "    mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=n_mfcc)\n",
        "    return mfccs.T\n",
        "\n",
        "def get_spectrogram(waveform):\n",
        "    # Convert the waveform to a spectrogram via a STFT.\n",
        "    spectrogram = tf.signal.stft(\n",
        "        waveform, frame_length=255, frame_step=128)\n",
        "    # Obtain the magnitude of the STFT.\n",
        "    spectrogram = tf.abs(spectrogram)\n",
        "    # Add a `channels` dimension, so that the spectrogram can be used\n",
        "    # as image-like input data with convolution layers (which expect\n",
        "    # shape (`batch_size`, `height`, `width`, `channels`).\n",
        "    spectrogram = spectrogram[..., tf.newaxis]\n",
        "    return spectrogram\n",
        "\n",
        "def process_audio(audio_path,target_length):\n",
        "    with wave.open(audio_path, 'rb') as wav_file:\n",
        "        frames = wav_file.readframes(-1)\n",
        "        num_channels = wav_file.getnchannels()\n",
        "\n",
        "        numpy_array = np.frombuffer(frames, dtype=np.float32)\n",
        "        # numpy_array = np.frombuffer(frames, dtype=np.int16)\n",
        "\n",
        "        if num_channels == 2:\n",
        "            numpy_array = numpy_array.reshape(-1, 2)\n",
        "\n",
        "        if len(numpy_array) < target_length:\n",
        "            padding_length = target_length - len(numpy_array)\n",
        "            if num_channels == 2:\n",
        "                numpy_array = np.pad(numpy_array, ((0, padding_length), (0, 0)), 'constant')\n",
        "            else:\n",
        "                numpy_array = np.pad(numpy_array, (0, padding_length), 'constant')\n",
        "\n",
        "        elif len(numpy_array) > target_length:\n",
        "            numpy_array = numpy_array[:target_length]\n",
        "\n",
        "        # mfcc = compute_mfcc(numpy_array,target_length)\n",
        "\n",
        "        return numpy_array.reshape((target_length,1))"
      ],
      "metadata": {
        "id": "BQsib4V_4oSl"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def audio_file_to_spectrogram(audio_path, target_length=16000):\n",
        "\n",
        "    with wave.open(audio_path, 'rb') as wav_file:\n",
        "        frames = wav_file.readframes(-1)\n",
        "        audio_array = np.frombuffer(frames, dtype=np.int16)\n",
        "\n",
        "        if len(audio_array) < target_length:\n",
        "            padding_length = target_length - len(audio_array)\n",
        "            audio_array = np.pad(audio_array, (0, padding_length), 'constant')\n",
        "        elif len(audio_array) > target_length:\n",
        "            audio_array = audio_array[:target_length]\n",
        "\n",
        "        _,_, spectrogram = signal.spectrogram(audio_array, fs=wav_file.getframerate())\n",
        "\n",
        "        return spectrogram"
      ],
      "metadata": {
        "id": "LH48mbUg_UkW"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DataSequence(tf.keras.utils.Sequence):\n",
        "\n",
        "    def __init__(self,data,batch_size=32,target_length=44100):\n",
        "        self.data = data\n",
        "        self.batch_size = batch_size\n",
        "        self.target_length = target_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.data) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "        batch = self.data[idx * self.batch_size : (idx + 1) * self.batch_size]\n",
        "        return self.data_gen(batch)\n",
        "\n",
        "    def data_gen(self,data):\n",
        "        audios,labels = list(),list()\n",
        "        for audio,label in data:\n",
        "            aud = audio_file_to_spectrogram(audio,self.target_length)\n",
        "            audios.append(aud)\n",
        "            labels.append(label)\n",
        "        return np.array(audios),np.array(labels)"
      ],
      "metadata": {
        "id": "V9Qdcw3C4rBU"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ratio = 0.7\n",
        "val_ratio = 0.1\n",
        "total_examples = len(data)\n",
        "train_size = round(total_examples * train_ratio)\n",
        "val_size = round(total_examples * val_ratio)\n",
        "train_examples = data[:train_size]\n",
        "val_examples = data[train_size:train_size+val_size]\n",
        "test_examples = data[train_size+val_size:]"
      ],
      "metadata": {
        "id": "tSukbkVm4s2G"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "sample_rate = 16000\n",
        "train_data = DataSequence(train_examples,batch_size,sample_rate)\n",
        "test_data = DataSequence(test_examples,1,sample_rate)\n",
        "eval_data = DataSequence(val_examples,batch_size,sample_rate)"
      ],
      "metadata": {
        "id": "Bh6O63NY42QU"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (*train_data[0][0].shape[1:],1)\n",
        "input_shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9qchLQwDfXe",
        "outputId": "170a2bcd-ba15-4681-8203-33c39be1e537"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(129, 71, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model = tf.keras.Sequential([\n",
        "#     tf.keras.layers.InputLayer(input_shape=list(train_data[1][0].shape[1:])),\n",
        "\n",
        "#     tf.keras.layers.Conv1D(32,3),\n",
        "#     tf.keras.layers.Activation('relu'),\n",
        "#     tf.keras.layers.Conv1D(32,3),\n",
        "#     tf.keras.layers.Activation('relu'),\n",
        "#     tf.keras.layers.Conv1D(64,3),\n",
        "#     tf.keras.layers.Activation('relu'),\n",
        "#     tf.keras.layers.MaxPooling1D(),\n",
        "#     tf.keras.layers.Dropout(0.25),\n",
        "#     tf.keras.layers.Flatten(),\n",
        "#     tf.keras.layers.Dense(512),\n",
        "#     tf.keras.layers.Activation('relu'),\n",
        "#     tf.keras.layers.Dense(128),\n",
        "#     tf.keras.layers.Activation('relu'),\n",
        "#     tf.keras.layers.Dense(64),\n",
        "#     tf.keras.layers.Activation('relu'),\n",
        "#     tf.keras.layers.Dropout(0.5),\n",
        "\n",
        "#     tf.keras.layers.Dense(len(categories)),\n",
        "#     tf.keras.layers.Activation('softmax'),\n",
        "# ])\n",
        "# model.compile(\n",
        "#     optimizer=tf.keras.optimizers.Adam(),\n",
        "#     loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "#     metrics=['accuracy']\n",
        "# )\n"
      ],
      "metadata": {
        "id": "UPn8gW-f43xU"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mobilnet_block(x,filters,strides):\n",
        "  x = tf.keras.layers.DepthwiseConv2D(kernel_size = 3, strides = strides, padding = 'same')(x)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.ReLU()(x)\n",
        "  x = tf.keras.layers.Conv2D(filters = filters, kernel_size = 1, strides = 1)(x)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.ReLU()(x)\n",
        "  return x\n",
        "\n",
        "_input = tf.keras.layers.Input(shape=input_shape)\n",
        "x = tf.keras.layers.Conv2D(filters = 32, kernel_size = 3, strides = 2, padding = 'same')(_input)\n",
        "x = tf.keras.layers.BatchNormalization()(x)\n",
        "x = tf.keras.layers.ReLU()(x)\n",
        "x = mobilnet_block(x, filters = 64, strides = 1)\n",
        "x = mobilnet_block(x, filters = 128, strides = 2)\n",
        "x = mobilnet_block(x, filters = 128, strides = 1)\n",
        "x = mobilnet_block(x, filters = 256, strides = 2)\n",
        "x = mobilnet_block(x, filters = 256, strides = 1)\n",
        "x = mobilnet_block(x, filters = 512, strides = 2)\n",
        "for _ in range (5):\n",
        "     x = mobilnet_block(x, filters = 512, strides = 1)\n",
        "x = mobilnet_block(x, filters = 1024, strides = 2)\n",
        "x = tf.keras.layers.Dropout(0.5)(x)\n",
        "x = mobilnet_block(x, filters = 1024, strides = 1)\n",
        "# x = tf.keras.layers.AvgPool2D(pool_size = 7, strides = 1, data_format='channels_first')(x)\n",
        "x = tf.keras.layers.Flatten()(x)\n",
        "output = tf.keras.layers.Dense(len(categories), activation = 'softmax', kernel_regularizer=tf.keras.regularizers.L2(l2=0.01))(x)\n",
        "model = tf.keras.Model(inputs=_input, outputs=output)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "uj1LJ1ECW3K0"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ji8QC9cr5EFk",
        "outputId": "5b0ed074-635f-471d-9bf0-e5825e595aac"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 129, 71, 1)]      0         \n",
            "                                                                 \n",
            " conv2d_28 (Conv2D)          (None, 65, 36, 32)        320       \n",
            "                                                                 \n",
            " batch_normalization_54 (Ba  (None, 65, 36, 32)        128       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " re_lu_54 (ReLU)             (None, 65, 36, 32)        0         \n",
            "                                                                 \n",
            " depthwise_conv2d_26 (Depth  (None, 65, 36, 32)        320       \n",
            " wiseConv2D)                                                     \n",
            "                                                                 \n",
            " batch_normalization_55 (Ba  (None, 65, 36, 32)        128       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " re_lu_55 (ReLU)             (None, 65, 36, 32)        0         \n",
            "                                                                 \n",
            " conv2d_29 (Conv2D)          (None, 65, 36, 64)        2112      \n",
            "                                                                 \n",
            " batch_normalization_56 (Ba  (None, 65, 36, 64)        256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " re_lu_56 (ReLU)             (None, 65, 36, 64)        0         \n",
            "                                                                 \n",
            " depthwise_conv2d_27 (Depth  (None, 33, 18, 64)        640       \n",
            " wiseConv2D)                                                     \n",
            "                                                                 \n",
            " batch_normalization_57 (Ba  (None, 33, 18, 64)        256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " re_lu_57 (ReLU)             (None, 33, 18, 64)        0         \n",
            "                                                                 \n",
            " conv2d_30 (Conv2D)          (None, 33, 18, 128)       8320      \n",
            "                                                                 \n",
            " batch_normalization_58 (Ba  (None, 33, 18, 128)       512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " re_lu_58 (ReLU)             (None, 33, 18, 128)       0         \n",
            "                                                                 \n",
            " depthwise_conv2d_28 (Depth  (None, 33, 18, 128)       1280      \n",
            " wiseConv2D)                                                     \n",
            "                                                                 \n",
            " batch_normalization_59 (Ba  (None, 33, 18, 128)       512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " re_lu_59 (ReLU)             (None, 33, 18, 128)       0         \n",
            "                                                                 \n",
            " conv2d_31 (Conv2D)          (None, 33, 18, 128)       16512     \n",
            "                                                                 \n",
            " batch_normalization_60 (Ba  (None, 33, 18, 128)       512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " re_lu_60 (ReLU)             (None, 33, 18, 128)       0         \n",
            "                                                                 \n",
            " depthwise_conv2d_29 (Depth  (None, 17, 9, 128)        1280      \n",
            " wiseConv2D)                                                     \n",
            "                                                                 \n",
            " batch_normalization_61 (Ba  (None, 17, 9, 128)        512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " re_lu_61 (ReLU)             (None, 17, 9, 128)        0         \n",
            "                                                                 \n",
            " conv2d_32 (Conv2D)          (None, 17, 9, 256)        33024     \n",
            "                                                                 \n",
            " batch_normalization_62 (Ba  (None, 17, 9, 256)        1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " re_lu_62 (ReLU)             (None, 17, 9, 256)        0         \n",
            "                                                                 \n",
            " depthwise_conv2d_30 (Depth  (None, 17, 9, 256)        2560      \n",
            " wiseConv2D)                                                     \n",
            "                                                                 \n",
            " batch_normalization_63 (Ba  (None, 17, 9, 256)        1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " re_lu_63 (ReLU)             (None, 17, 9, 256)        0         \n",
            "                                                                 \n",
            " conv2d_33 (Conv2D)          (None, 17, 9, 256)        65792     \n",
            "                                                                 \n",
            " batch_normalization_64 (Ba  (None, 17, 9, 256)        1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " re_lu_64 (ReLU)             (None, 17, 9, 256)        0         \n",
            "                                                                 \n",
            " depthwise_conv2d_31 (Depth  (None, 9, 5, 256)         2560      \n",
            " wiseConv2D)                                                     \n",
            "                                                                 \n",
            " batch_normalization_65 (Ba  (None, 9, 5, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " re_lu_65 (ReLU)             (None, 9, 5, 256)         0         \n",
            "                                                                 \n",
            " conv2d_34 (Conv2D)          (None, 9, 5, 512)         131584    \n",
            "                                                                 \n",
            " batch_normalization_66 (Ba  (None, 9, 5, 512)         2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " re_lu_66 (ReLU)             (None, 9, 5, 512)         0         \n",
            "                                                                 \n",
            " depthwise_conv2d_32 (Depth  (None, 9, 5, 512)         5120      \n",
            " wiseConv2D)                                                     \n",
            "                                                                 \n",
            " batch_normalization_67 (Ba  (None, 9, 5, 512)         2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " re_lu_67 (ReLU)             (None, 9, 5, 512)         0         \n",
            "                                                                 \n",
            " conv2d_35 (Conv2D)          (None, 9, 5, 512)         262656    \n",
            "                                                                 \n",
            " batch_normalization_68 (Ba  (None, 9, 5, 512)         2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " re_lu_68 (ReLU)             (None, 9, 5, 512)         0         \n",
            "                                                                 \n",
            " depthwise_conv2d_33 (Depth  (None, 9, 5, 512)         5120      \n",
            " wiseConv2D)                                                     \n",
            "                                                                 \n",
            " batch_normalization_69 (Ba  (None, 9, 5, 512)         2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " re_lu_69 (ReLU)             (None, 9, 5, 512)         0         \n",
            "                                                                 \n",
            " conv2d_36 (Conv2D)          (None, 9, 5, 512)         262656    \n",
            "                                                                 \n",
            " batch_normalization_70 (Ba  (None, 9, 5, 512)         2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " re_lu_70 (ReLU)             (None, 9, 5, 512)         0         \n",
            "                                                                 \n",
            " depthwise_conv2d_34 (Depth  (None, 9, 5, 512)         5120      \n",
            " wiseConv2D)                                                     \n",
            "                                                                 \n",
            " batch_normalization_71 (Ba  (None, 9, 5, 512)         2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " re_lu_71 (ReLU)             (None, 9, 5, 512)         0         \n",
            "                                                                 \n",
            " conv2d_37 (Conv2D)          (None, 9, 5, 512)         262656    \n",
            "                                                                 \n",
            " batch_normalization_72 (Ba  (None, 9, 5, 512)         2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " re_lu_72 (ReLU)             (None, 9, 5, 512)         0         \n",
            "                                                                 \n",
            " depthwise_conv2d_35 (Depth  (None, 9, 5, 512)         5120      \n",
            " wiseConv2D)                                                     \n",
            "                                                                 \n",
            " batch_normalization_73 (Ba  (None, 9, 5, 512)         2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " re_lu_73 (ReLU)             (None, 9, 5, 512)         0         \n",
            "                                                                 \n",
            " conv2d_38 (Conv2D)          (None, 9, 5, 512)         262656    \n",
            "                                                                 \n",
            " batch_normalization_74 (Ba  (None, 9, 5, 512)         2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " re_lu_74 (ReLU)             (None, 9, 5, 512)         0         \n",
            "                                                                 \n",
            " depthwise_conv2d_36 (Depth  (None, 9, 5, 512)         5120      \n",
            " wiseConv2D)                                                     \n",
            "                                                                 \n",
            " batch_normalization_75 (Ba  (None, 9, 5, 512)         2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " re_lu_75 (ReLU)             (None, 9, 5, 512)         0         \n",
            "                                                                 \n",
            " conv2d_39 (Conv2D)          (None, 9, 5, 512)         262656    \n",
            "                                                                 \n",
            " batch_normalization_76 (Ba  (None, 9, 5, 512)         2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " re_lu_76 (ReLU)             (None, 9, 5, 512)         0         \n",
            "                                                                 \n",
            " depthwise_conv2d_37 (Depth  (None, 5, 3, 512)         5120      \n",
            " wiseConv2D)                                                     \n",
            "                                                                 \n",
            " batch_normalization_77 (Ba  (None, 5, 3, 512)         2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " re_lu_77 (ReLU)             (None, 5, 3, 512)         0         \n",
            "                                                                 \n",
            " conv2d_40 (Conv2D)          (None, 5, 3, 1024)        525312    \n",
            "                                                                 \n",
            " batch_normalization_78 (Ba  (None, 5, 3, 1024)        4096      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " re_lu_78 (ReLU)             (None, 5, 3, 1024)        0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 5, 3, 1024)        0         \n",
            "                                                                 \n",
            " depthwise_conv2d_38 (Depth  (None, 5, 3, 1024)        10240     \n",
            " wiseConv2D)                                                     \n",
            "                                                                 \n",
            " batch_normalization_79 (Ba  (None, 5, 3, 1024)        4096      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " re_lu_79 (ReLU)             (None, 5, 3, 1024)        0         \n",
            "                                                                 \n",
            " conv2d_41 (Conv2D)          (None, 5, 3, 1024)        1049600   \n",
            "                                                                 \n",
            " batch_normalization_80 (Ba  (None, 5, 3, 1024)        4096      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " re_lu_80 (ReLU)             (None, 5, 3, 1024)        0         \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 15360)             0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 8)                 122888    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3362120 (12.83 MB)\n",
            "Trainable params: 3340232 (12.74 MB)\n",
            "Non-trainable params: 21888 (85.50 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.device('gpu:0'):\n",
        "  history = model.fit(train_data,epochs=25,validation_data=eval_data,verbose=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mze6FFUl46j1",
        "outputId": "41dd8658-306c-4777-cd7f-f35289ae7010"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "175/175 [==============================] - 11s 60ms/step - loss: 0.3037 - accuracy: 0.9095 - val_loss: 3.6441 - val_accuracy: 0.2375\n",
            "Epoch 2/25\n",
            "175/175 [==============================] - 8s 46ms/step - loss: 0.2881 - accuracy: 0.9145 - val_loss: 4.2777 - val_accuracy: 0.2062\n",
            "Epoch 3/25\n",
            "175/175 [==============================] - 9s 50ms/step - loss: 0.2298 - accuracy: 0.9304 - val_loss: 2.3510 - val_accuracy: 0.3988\n",
            "Epoch 4/25\n",
            "175/175 [==============================] - 9s 50ms/step - loss: 0.1939 - accuracy: 0.9475 - val_loss: 3.4053 - val_accuracy: 0.2837\n",
            "Epoch 5/25\n",
            "175/175 [==============================] - 8s 46ms/step - loss: 0.2179 - accuracy: 0.9364 - val_loss: 4.0659 - val_accuracy: 0.1950\n",
            "Epoch 6/25\n",
            "175/175 [==============================] - 9s 49ms/step - loss: 0.1708 - accuracy: 0.9516 - val_loss: 2.9478 - val_accuracy: 0.3700\n",
            "Epoch 7/25\n",
            "175/175 [==============================] - 9s 50ms/step - loss: 0.1674 - accuracy: 0.9489 - val_loss: 7.3090 - val_accuracy: 0.1400\n",
            "Epoch 8/25\n",
            "175/175 [==============================] - 9s 49ms/step - loss: 0.1719 - accuracy: 0.9529 - val_loss: 3.8811 - val_accuracy: 0.3150\n",
            "Epoch 9/25\n",
            "175/175 [==============================] - 8s 47ms/step - loss: 0.2189 - accuracy: 0.9366 - val_loss: 2.4657 - val_accuracy: 0.2037\n",
            "Epoch 10/25\n",
            "175/175 [==============================] - 9s 50ms/step - loss: 0.1632 - accuracy: 0.9555 - val_loss: 2.8655 - val_accuracy: 0.2825\n",
            "Epoch 11/25\n",
            "175/175 [==============================] - 9s 49ms/step - loss: 0.1427 - accuracy: 0.9586 - val_loss: 2.0167 - val_accuracy: 0.5550\n",
            "Epoch 12/25\n",
            "175/175 [==============================] - 8s 45ms/step - loss: 0.1494 - accuracy: 0.9589 - val_loss: 3.0715 - val_accuracy: 0.4462\n",
            "Epoch 13/25\n",
            "175/175 [==============================] - 9s 50ms/step - loss: 0.1256 - accuracy: 0.9668 - val_loss: 2.8464 - val_accuracy: 0.3875\n",
            "Epoch 14/25\n",
            "175/175 [==============================] - 9s 49ms/step - loss: 0.1370 - accuracy: 0.9638 - val_loss: 3.1351 - val_accuracy: 0.3100\n",
            "Epoch 15/25\n",
            "175/175 [==============================] - 8s 46ms/step - loss: 0.1216 - accuracy: 0.9654 - val_loss: 3.6924 - val_accuracy: 0.2962\n",
            "Epoch 16/25\n",
            "175/175 [==============================] - 9s 50ms/step - loss: 0.0819 - accuracy: 0.9809 - val_loss: 2.2655 - val_accuracy: 0.4638\n",
            "Epoch 17/25\n",
            "175/175 [==============================] - 9s 50ms/step - loss: 0.1291 - accuracy: 0.9664 - val_loss: 3.2471 - val_accuracy: 0.3787\n",
            "Epoch 18/25\n",
            "175/175 [==============================] - 9s 49ms/step - loss: 0.1720 - accuracy: 0.9555 - val_loss: 2.5359 - val_accuracy: 0.4375\n",
            "Epoch 19/25\n",
            "175/175 [==============================] - 8s 48ms/step - loss: 0.1222 - accuracy: 0.9689 - val_loss: 4.8644 - val_accuracy: 0.2062\n",
            "Epoch 20/25\n",
            "175/175 [==============================] - 9s 53ms/step - loss: 0.0678 - accuracy: 0.9836 - val_loss: 2.3846 - val_accuracy: 0.4950\n",
            "Epoch 21/25\n",
            "175/175 [==============================] - 9s 49ms/step - loss: 0.1045 - accuracy: 0.9741 - val_loss: 1.5813 - val_accuracy: 0.5750\n",
            "Epoch 22/25\n",
            "175/175 [==============================] - 8s 45ms/step - loss: 0.0970 - accuracy: 0.9745 - val_loss: 1.5238 - val_accuracy: 0.5913\n",
            "Epoch 23/25\n",
            "175/175 [==============================] - 9s 50ms/step - loss: 0.1097 - accuracy: 0.9711 - val_loss: 3.7759 - val_accuracy: 0.2637\n",
            "Epoch 24/25\n",
            "175/175 [==============================] - 9s 50ms/step - loss: 0.1199 - accuracy: 0.9680 - val_loss: 2.4630 - val_accuracy: 0.4638\n",
            "Epoch 25/25\n",
            "175/175 [==============================] - 8s 45ms/step - loss: 0.1268 - accuracy: 0.9673 - val_loss: 1.8686 - val_accuracy: 0.5175\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = [i[0] for _,i in test_data]\n",
        "y_pred = [np.argmax(i) for i in model.predict(test_data)]"
      ],
      "metadata": {
        "id": "2e93_f5D69Wk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conf_mat = tf.math.confusion_matrix(y_true,y_pred)"
      ],
      "metadata": {
        "id": "VtpDIYUGrRbY"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(conf_mat)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "CCK-NAXArR4H",
        "outputId": "ab10b899-6be7-4ec9-c03b-bd969a85cabc"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('classifier.h5')\n",
        "from google.colab import files\n",
        "files.download('classifier.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "9WEBv2hkrdUW",
        "outputId": "bcf59b41-7ddd-453d-b167-103a058f1034"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c13959b3-c044-4224-915b-0967d8393dec\", \"classifier.h5\", 40650320)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uzM4MWkWrpmI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}